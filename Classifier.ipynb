{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMQAFNjaH6cF",
        "outputId": "be24f7bf-764b-4248-c3d0-6af38a15556c"
      },
      "id": "NMQAFNjaH6cF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b1a20580",
      "metadata": {
        "id": "b1a20580"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cv_data(index):\n",
        "  x_train = np.load(f\"drive/MyDrive/DreamWalker/pre_train/Cla/kmer_train_{index}.npz\")[\"data\"]\n",
        "  y_train = np.load(f\"drive/MyDrive/DreamWalker/pre_train/Cla/lineage_train_{index}.npz\")[\"data\"]\n",
        "  x_val = np.load(f\"drive/MyDrive/DreamWalker/pre_train/Cla/kmer_val_{index}.npz\")[\"data\"]\n",
        "  y_val = np.load(f\"drive/MyDrive/DreamWalker/pre_train/Cla/lineage_val_{index}.npz\")[\"data\"]\n",
        "  return x_train, y_train, x_val, y_val"
      ],
      "metadata": {
        "id": "p_6yzavWP754"
      },
      "id": "p_6yzavWP754",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.load(\"drive/MyDrive/DreamWalker/model_weights/LineageTV_vocal.npy\")"
      ],
      "metadata": {
        "id": "VNVCSLEZO4yA"
      },
      "id": "VNVCSLEZO4yA",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "69166a47",
      "metadata": {
        "id": "69166a47"
      },
      "outputs": [],
      "source": [
        "def create_ann(vocab_size, length):\n",
        "    encoder_inputs = tf.keras.layers.Input(shape=(1024,))\n",
        "    x = tf.keras.layers.RepeatVector(length, name=\"RepeatVector\")(encoder_inputs)\n",
        "    x = tf.keras.layers.GRU(1024, return_sequences=True, dropout=0.2, name=\"GRU0\")(x)\n",
        "    x = tf.keras.layers.GRU(1024, return_sequences=True, dropout=0.2, name=\"GRU1\")(x)\n",
        "    x = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "    model = tf.keras.models.Model(encoder_inputs,x)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8245b006",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8245b006",
        "outputId": "be381763-fa50-4345-dd8a-b77548012181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9977203647416414, 0.9936676798378926, 0.9934143870314083, 0.9875886524822695, 0.9736575481256332, 0.9516210739614995, 0.7160587639311043, 0.9924012158054711, 0.9954407294832827, 0.9929078014184397, 0.9878419452887538, 0.9766970618034447, 0.9690982776089159, 0.9825227963525835, 0.9984802431610942, 0.99822695035461, 0.993920972644377, 0.9962006079027356, 0.9962006079027356]\n",
            "[0.9992401215805471, 0.9962006079027356, 0.9944275582573455, 0.9878419452887538, 0.9761904761904762, 0.950354609929078, 0.7001013171225937, 0.9924012158054711, 0.9951874366767984, 0.9934143870314083, 0.9918946301925026, 0.9842958459979737, 0.9782168186423505, 0.9858156028368794, 0.99822695035461, 0.99822695035461, 0.9951874366767984, 0.995694022289767, 0.9967071935157041]\n",
            "[0.997467071935157, 0.9959473150962512, 0.9941742654508612, 0.9911347517730497, 0.975177304964539, 0.9521276595744681, 0.7302431610942249, 0.9924012158054711, 0.9941742654508612, 0.9946808510638298, 0.9893617021276596, 0.9850557244174265, 0.9804964539007093, 0.9875886524822695, 0.9992401215805471, 0.9989868287740629, 0.9941742654508612, 0.995694022289767, 0.9987335359675785]\n",
            "[0.9984802431610942, 0.993920972644377, 0.9926545086119554, 0.9850557244174265, 0.9698581560283688, 0.9447821681864235, 0.7218844984802432, 0.9898682877406282, 0.9918946301925026, 0.9921479229989868, 0.9888551165146909, 0.9812563323201621, 0.9759371833839919, 0.9873353596757852, 0.99822695035461, 0.997467071935157, 0.9962006079027356, 0.9964539007092199, 0.9962006079027356]\n",
            "[0.9984802431610942, 0.9962006079027356, 0.9946808510638298, 0.9868287740628167, 0.9728976697061803, 0.955420466058764, 0.7061803444782169, 0.9903748733535968, 0.9946808510638298, 0.9954407294832827, 0.9911347517730497, 0.9810030395136778, 0.9756838905775076, 0.9830293819655522, 0.9969604863221885, 0.9969604863221885, 0.9916413373860182, 0.9934143870314083, 0.9949341438703141]\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "ann_accuracy_records = {}\n",
        "vocab_size = len(vocab)\n",
        "for j in range(5):\n",
        "    # train\n",
        "    x_train, y_train, x_val, y_val = load_cv_data(j)\n",
        "    length = y_train.shape[1]\n",
        "    model = create_ann(vocab_size, length)\n",
        "    model.fit(x_train, y_train, batch_size=32, epochs=EPOCHS, verbose=0, validation_data=(x_val, y_val))\n",
        "    # val\n",
        "    ann_pred = model.predict(x_val, verbose=0)\n",
        "    pred_argmax = np.argmax(ann_pred, axis=2)\n",
        "    accuracy_record = []\n",
        "    for i in range(length):\n",
        "        accuracy = accuracy_score(pred_argmax[:,i], y_val[:,i])\n",
        "        accuracy_record.append(accuracy)\n",
        "    print(accuracy_record)\n",
        "    ann_accuracy_records[j] = accuracy_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1d84b6a3",
      "metadata": {
        "id": "1d84b6a3"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(ann_accuracy_records).transpose().to_csv(\"drive/MyDrive/DreamWalker/pre_train/cla_cv_accuracy.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"drive/MyDrive/DreamWalker/pre_train/Cla/kmer_train.npz\")[\"data\"]\n",
        "y_train = np.load(\"drive/MyDrive/DreamWalker/pre_train/Cla/lineage_train.npz\")[\"data\"]\n",
        "x_test = np.load(\"drive/MyDrive/DreamWalker/pre_train/Cla/kmer_test.npz\")[\"data\"]\n",
        "y_test = np.load(\"drive/MyDrive/DreamWalker/pre_train/Cla/lineage_test.npz\")[\"data\"]\n",
        "# train\n",
        "model = create_ann(vocab_size, y_train.shape[1])\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=20, verbose=0)\n",
        "# test\n",
        "ann_pred = model.predict(x_test, verbose=0)\n",
        "pred_argmax = np.argmax(ann_pred, axis=2)\n",
        "accuracy_record = []\n",
        "for i in range(y_test.shape[1]):\n",
        "    accuracy = accuracy_score(pred_argmax[:,i], y_test[:,i])\n",
        "    accuracy_record.append(accuracy)\n",
        "print(accuracy_record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLjTtuk2NbXw",
        "outputId": "b2ee526f-9e5b-4479-cb89-d70e8f03f182"
      },
      "id": "uLjTtuk2NbXw",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9995440729483283, 0.9977203647416414, 0.9969604863221885, 0.9930091185410335, 0.9797872340425532, 0.9617021276595744, 0.7480243161094224, 0.9954407294832827, 0.9972644376899696, 0.9972644376899696, 0.9936170212765958, 0.9864741641337386, 0.9828267477203647, 0.9875379939209726, 0.997872340425532, 0.9990881458966565, 0.9954407294832827, 0.9965045592705167, 0.9954407294832827]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.load(\"drive/MyDrive/DreamWalker/pre_train/Cla/kmer_whole.npz\")[\"data\"]\n",
        "y = np.load(\"drive/MyDrive/DreamWalker/pre_train/Cla/lineage_whole.npz\")[\"data\"]\n",
        "model.fit(x, y, batch_size=32, epochs=20, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t_M7irXqa_B",
        "outputId": "96652bf0-2cf1-4617-b31b-cfec81469a0c"
      },
      "id": "9t_M7irXqa_B",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7842cbb6e980>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f37e7bd8",
      "metadata": {
        "id": "f37e7bd8"
      },
      "outputs": [],
      "source": [
        "# model.save(\"drive/MyDrive/DreamWalker/model_weights/classifier.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1b07e7fa",
      "metadata": {
        "id": "1b07e7fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854489e3-4a63-4e90-8670-474f541510ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:716: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  val = np.asanyarray(val)\n"
          ]
        }
      ],
      "source": [
        "path = \"drive/MyDrive/DreamWalker/model_weights/ClassifierWeights\"\n",
        "for i, layer in enumerate(model.layers):\n",
        "    weights = layer.get_weights()\n",
        "    np.savez_compressed(f'{path}/layer_{i}_weights', weights=weights)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}