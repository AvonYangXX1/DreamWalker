{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "BP9ZtYGEi8MX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zcmQm7pNgxG"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97gu1WVpNi4s",
        "outputId": "54a725fe-6d3d-4618-fc22-51ec459a2b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[21  6  2 ...  0  0  0]\n",
            " [21  4 15 ...  0  0  0]\n",
            " [21  4 15 ...  0  0  0]\n",
            " ...\n",
            " [21 11 17 ...  0  0  0]\n",
            " [21 18  5 ...  0  0  0]\n",
            " [21 12  5 ...  0  0  0]]\n",
            "(1078141, 40)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# path = \"/content/DreamWalker/data/processed_data/GAN\"\n",
        "pretrain_sequences = np.load(\"enc_uniprot.npz\")['data']\n",
        "print(pretrain_sequences)\n",
        "print(pretrain_sequences.shape)\n",
        "print(type(pretrain_sequences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gCSx_kQ022rL"
      },
      "outputs": [],
      "source": [
        "# Config\n",
        "vocab_size = 23\n",
        "seq_length = 40\n",
        "embed_dim = 64\n",
        "num_transformer_blocks = 4\n",
        "num_heads = 8\n",
        "ff_dim =512\n",
        "batch_size = 64\n",
        "lr = 1e-4\n",
        "np.random.seed(8701)\n",
        "noise_level = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mFruVBnGPFC_"
      },
      "outputs": [],
      "source": [
        "# Convert your NumPy array to a TensorFlow tensor\n",
        "sequences_tensor = tf.constant(pretrain_sequences, dtype=tf.int32)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(sequences_tensor)\n",
        "dataset = dataset.shuffle(buffer_size=10000).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9NJldHbFNmU7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Add noise to the sequence\n",
        "# I still think this is a necessary step to add to the pre_training process\n",
        "\n",
        "# def add_noise(sequences, noise_level):\n",
        "#     num_sequences, sequence_length = sequences.shape\n",
        "#     num_amino_acids = 21  # Including a 'noise' token\n",
        "#     num_noisy_positions = tf.cast(sequence_length * noise_level, tf.int32)\n",
        "#     positions = tf.random.uniform((num_sequences, num_noisy_positions),\n",
        "#                                   minval=0, maxval=sequence_length, dtype=tf.int32)\n",
        "\n",
        "#     noise_values = tf.random.uniform((num_sequences, num_noisy_positions),\n",
        "#                                      minval=1, maxval=num_amino_acids, dtype=tf.int32)\n",
        "\n",
        "#     mask = tf.sequence_mask(positions, sequence_length)\n",
        "#     sequences = tf.where(mask, noise_values, sequences)\n",
        "\n",
        "#     return sequences\n",
        "\n",
        "def add_noise(sequences, noise_level):\n",
        "    num_sequences, sequence_length = sequences.shape\n",
        "    # Correct range for indices [0, 21], ensuring no index exceeds 21\n",
        "    num_amino_acids = 22 # This means indices can go up to 21, as the upper bound is exclusive in tf.random.uniform\n",
        "\n",
        "    # Create a noise mask with the same shape as sequences\n",
        "    noise_mask = tf.random.uniform(shape=tf.shape(sequences), minval=0, maxval=1.0) < noise_level\n",
        "\n",
        "    # Generate noise values within the correct range\n",
        "    noise_values = tf.random.uniform(\n",
        "        shape=tf.shape(sequences), minval=0, maxval=num_amino_acids, dtype=tf.int32)\n",
        "\n",
        "    # Apply noise where mask is True, else keep original sequence\n",
        "    noised_sequences = tf.where(noise_mask, noise_values, sequences)\n",
        "\n",
        "    return noised_sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbbswPGyg_h"
      },
      "source": [
        "## Diffusion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9UXkQYgB9I_"
      },
      "source": [
        "### Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3LJte948D-Yd"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\n",
        "class TransformerDecoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerDecoderBlock, self).__init__()\n",
        "        self.att1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.att2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)  # For skip connections\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "        self.dropout3 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, enc_output, training):\n",
        "        attn1_output = self.att1(inputs, inputs)\n",
        "        attn1_output = self.dropout1(attn1_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn1_output)\n",
        "\n",
        "        # Skip Connection\n",
        "        attn2_output = self.att2(out1, enc_output)\n",
        "        attn2_output = self.dropout2(attn2_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2_output)\n",
        "\n",
        "        # Feed forward network\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        return self.layernorm3(out2 + ffn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T_BWjmcyakhG"
      },
      "outputs": [],
      "source": [
        "def build_amp_diffusion_unet(vocab_size, seq_length, embed_dim, num_transformer_blocks, num_heads, ff_dim):\n",
        "    sequence_input = layers.Input(shape=(seq_length,), dtype='int32')\n",
        "\n",
        "    x = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(sequence_input)\n",
        "\n",
        "    # Encoder\n",
        "    skip_connections = []\n",
        "    for _ in range(num_transformer_blocks // 2):\n",
        "        x = TransformerEncoderBlock(embed_dim, num_heads, ff_dim)(x)\n",
        "        skip_connections.append(x)\n",
        "\n",
        "    # Decoder\n",
        "    for i in range(num_transformer_blocks // 2):\n",
        "        enc_output = skip_connections[-(i + 1)]\n",
        "        x = TransformerDecoderBlock(embed_dim, num_heads, ff_dim)(x, enc_output)\n",
        "\n",
        "    x = layers.Dense(vocab_size)(x)  # Ensure this is logits for numerical stability\n",
        "\n",
        "    return models.Model(inputs=sequence_input, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lnz4oPG1xl0u"
      },
      "outputs": [],
      "source": [
        "# # diffusion model\n",
        "# class UNetDiffusionModel(models.Model):\n",
        "#     def __init__(self, vocab_size, max_length, embed_dim):\n",
        "#         super(UNetDiffusionModel, self).__init__()\n",
        "#         self.embedding = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "\n",
        "#         # Define the U-Net architecture with Transformer blocks\n",
        "#         self.encoder = [TransformerBlock(embed_dim=embed_dim, num_heads=8, ff_dim=512) for _ in range(3)]\n",
        "#         self.decoder = [TransformerBlock(embed_dim=embed_dim, num_heads=8, ff_dim=512) for _ in range(3)]\n",
        "\n",
        "#         self.output_layer = layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         x = self.embedding(inputs)\n",
        "\n",
        "#         for layer in self.encoder:\n",
        "#             x = layer(x)\n",
        "\n",
        "#         for layer in self.decoder:\n",
        "#             x = layer(x)\n",
        "\n",
        "#         return self.output_layer(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h1i8-RNBE3DO"
      },
      "outputs": [],
      "source": [
        "# Compile AMP_Diffusion\n",
        "\n",
        "# def build_amp_diffusion_unet(vocab_size, seq_length, embed_dim, num_transformer_blocks, num_heads, ff_dim):\n",
        "#     sequence_input = layers.Input(shape=(seq_length,), dtype='int32')\n",
        "#     timestep_input = layers.Input(shape=(1,))\n",
        "\n",
        "#     x = layers.Embedding(input_dim=23, output_dim=embed_dim)(sequence_input)\n",
        "\n",
        "#     # Encoder\n",
        "#     skip_connections = []\n",
        "#     for _ in range(num_transformer_blocks // 2):  # an equal split assumption\n",
        "#         x = TransformerEncoderBlock(embed_dim, num_heads, ff_dim)(x)\n",
        "#         skip_connections.append(x)\n",
        "\n",
        "#     # Decoder\n",
        "#     for i in range(num_transformer_blocks // 2):\n",
        "#         enc_output = skip_connections[-(i+1)]\n",
        "#         x = TransformerDecoderBlock(embed_dim, num_heads, ff_dim)(x, enc_output)\n",
        "\n",
        "#     x = layers.Dense(vocab_size, activation='softmax')(x)\n",
        "\n",
        "#     return models.Model(inputs=[sequence_input, timestep_input], outputs=x)\n",
        "# Adjusted Output Layer of the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HT8YMobVPvGi"
      },
      "outputs": [],
      "source": [
        "model = build_amp_diffusion_unet(vocab_size, seq_length, embed_dim,num_transformer_blocks, num_heads, ff_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9MGOKnnPQHah"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, sequences, optimizer, loss_fn, noise_level):\n",
        "    with tf.GradientTape() as tape:\n",
        "        noised_sequences = add_noise(sequences, noise_level)\n",
        "        predictions = model(noised_sequences, training=True)\n",
        "        loss = loss_fn(sequences, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "qEX6dzONPpaL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "import datetime\n"
      ],
      "metadata": {
        "id": "MEYZ-uYUiuBu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "    for batch_sequences in dataset:\n",
        "        loss = train_step(model, batch_sequences, optimizer, loss_fn, noise_level)\n",
        "        epoch_loss_avg.update_state(loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Loss: {epoch_loss_avg.result().numpy()}\")\n",
        "\n",
        "model.save('UNet_Diffusion.h5')"
      ],
      "metadata": {
        "id": "9KxyWjFqiwNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea8cc4c-0cec-455d-8680-c07562090ceb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7a5babb35bd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7a5babb35bd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 0.5315845608711243\n",
            "Epoch 2/5\n",
            "Epoch 2: Loss: 0.5270335078239441\n",
            "Epoch 3/5\n",
            "Epoch 3: Loss: 0.5263277292251587\n",
            "Epoch 4/5\n",
            "Epoch 4: Loss: 0.5258371233940125\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.5253657698631287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nTDqv2DyvaFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZgWX6kKrzKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "6e92976d-cc70-4f92-b2f4-59a757413423"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-feea18dc3ab6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UNet_Diffusion.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.save('UNet_Diffusion.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jtISP1FCjJiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}